{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901515a0-4da8-479c-9705-e77837a7be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774cff5a-dd4e-41e4-aede-222d35e85a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\", \"Stuttgart\", \"Frankfurt\", \"Düsseldorf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fb0e83-7707-420d-be2b-fd64f1fed4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_id        city\n",
      "0        1      Berlin\n",
      "1        2     Hamburg\n",
      "2        3      Munich\n",
      "3        4   Stuttgart\n",
      "4        5   Frankfurt\n",
      "5        6  Düsseldorf\n"
     ]
    }
   ],
   "source": [
    "cities_df = pd.DataFrame({\"city_id\": range(1, len(cities) + 1), \"city\": cities})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ed0d97-f398-484d-8c00-801e12d131a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = \"sql_workshop_cities\"\n",
    "host = \"127.0.0.1\"\n",
    "user = \"root\"\n",
    "password = \"my-pass\"\n",
    "port = 3306\n",
    "\n",
    "connection_string = f'mysqlpass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14a0564-1182-45d5-9586-35ed09f64413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.to_sql('cities',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "abe66d7e-5c94-4c73-8817-ddc391c7e1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_id  country  population   latitude  longitude\n",
      "0        1  Germany   3850809.0  52.520000  13.405000\n",
      "1        2  Germany   1945532.0        NaN        NaN\n",
      "2        3  Germany   1512491.0  48.137500  11.575000\n",
      "3        4  Germany    626275.0  48.777500   9.180000\n",
      "4        5  Germany         NaN  50.110556   8.682222\n",
      "5        6  Germany    619477.0        NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\", \"Stuttgart\", \"Frankfurt\", \"Düsseldorf\"]\n",
    "\n",
    "def extract_city_info(city: str):\n",
    "    def clean_population(population_str):\n",
    "        return re.sub(r'[^\\d]', '', population_str)\n",
    "\n",
    "    city_data = {}\n",
    "    url = f\"https://www.wikipedia.org/wiki/{city}\"\n",
    "    response = requests.get(url)\n",
    "    city_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    city_data[\"city\"] = city\n",
    "    city_data[\"country\"] = city_soup.find(class_=\"infobox-data\").get_text()\n",
    "\n",
    "    population_tag = city_soup.find(string=re.compile(\"Population\"))\n",
    "    if population_tag:\n",
    "        city_population = population_tag.find_next(\"td\").get_text()\n",
    "        city_population_clean = clean_population(city_population)\n",
    "        \n",
    "        if city_population_clean:\n",
    "            city_data[\"population\"] = int(city_population_clean)\n",
    "        else:\n",
    "            city_data[\"population\"] = None\n",
    "    else:\n",
    "        city_data[\"population\"] = None\n",
    "\n",
    "    city_data[\"latitude\"] = city_soup.find(class_=\"latitude\").get_text()\n",
    "    city_data[\"longitude\"] = city_soup.find(class_=\"longitude\").get_text()\n",
    "\n",
    "    return city_data\n",
    "\n",
    "def transform_coordinates(lat_str, lon_str):\n",
    "    def dms_to_dd(degrees, minutes, seconds, direction):\n",
    "        dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "        if direction == 'S' or direction == 'W':\n",
    "            dd *= -1\n",
    "        return dd\n",
    "\n",
    "    try:\n",
    "        lat_parts = re.split('[^\\d.]+', lat_str)\n",
    "        lon_parts = re.split('[^\\d.]+', lon_str)\n",
    "\n",
    "        if len(lat_parts) >= 4 and len(lon_parts) >= 4:\n",
    "            lat_deg, lat_min, lat_sec, lat_dir = lat_parts[:4]\n",
    "            lon_deg, lon_min, lon_sec, lon_dir = lon_parts[:4]\n",
    "\n",
    "            lat_decimal = dms_to_dd(lat_deg, lat_min, lat_sec, lat_dir)\n",
    "            lon_decimal = dms_to_dd(lon_deg, lon_min, lon_sec, lon_dir)\n",
    "\n",
    "            return lat_decimal, lon_decimal\n",
    "        else:\n",
    "            raise ValueError(\"Invalid format for latitude or longitude\")\n",
    "    except ValueError:\n",
    "        return None, None\n",
    "\n",
    "def process_cities(cities, cities_df):\n",
    "    processed_data = []\n",
    "\n",
    "    for city in cities:\n",
    "        city_info = extract_city_info(city)\n",
    "        lat_decimal, lon_decimal = transform_coordinates(city_info[\"latitude\"], city_info[\"longitude\"])\n",
    "        city_info[\"latitude\"] = lat_decimal\n",
    "        city_info[\"longitude\"] = lon_decimal\n",
    "\n",
    "        city_id = cities_df[cities_df['city'] == city]['city_id'].values[0]\n",
    "        city_info[\"city_id\"] = city_id\n",
    "\n",
    "        processed_data.append(city_info)\n",
    "\n",
    "    cities_facts_df = pd.DataFrame(processed_data)\n",
    "    columns_order = ['city_id'] + [col for col in cities_facts_df.columns if col != 'city_id']\n",
    "    cities_facts_df = cities_facts_df[columns_order]\n",
    "\n",
    "    return cities_facts_df\n",
    "\n",
    "# Assuming cities_df is the dataframe containing 'city' and 'city_id'\n",
    "cities_facts_df = process_cities(cities, cities_df).drop(columns=['city'])\n",
    "\n",
    "cities_facts_df.to_sql('cities_facts',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)\n",
    "print(cities_facts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d142eb8-7fbd-49da-ab3c-7e863952e619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data successfully sent to MySQL database!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data has been updated'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the cities list\n",
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\", \"Stuttgart\", \"Frankfurt\", \"Düsseldorf\"]\n",
    "\n",
    "# Create cities_df\n",
    "cities_df = pd.DataFrame({\"city_id\": range(1, len(cities) + 1), \"city\": cities})\n",
    "\n",
    "def retreiving_and_sending_weather_data():\n",
    "    weather_df = get_weather_data(cities_df)\n",
    "    send_weather_data(weather_df, connection_string)\n",
    "    return \"Data has been updated\"\n",
    "\n",
    "def get_weather_data(cities_df):\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    API_key = 'my-api'\n",
    "    weather_items = []\n",
    "\n",
    "    for city_id, city in zip(cities_df[\"city_id\"], cities_df[\"city\"]):\n",
    "        # Construct the API URL for each city\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={API_key}&units=metric\"\n",
    "        \n",
    "        # Make the API request\n",
    "        response = requests.get(url)\n",
    "        json_data = response.json()\n",
    "\n",
    "        # Get the current time in Berlin timezone\n",
    "        retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Extract weather information from the API response\n",
    "        for item in json_data[\"list\"]:\n",
    "            weather_item = {\n",
    "                \"city_id\": city_id,\n",
    "                \"forecast_time\": item.get(\"dt_txt\", None),\n",
    "                \"temperature\": item[\"main\"].get(\"temp\", None),\n",
    "                \"forecast\": item[\"weather\"][0].get(\"main\", None),\n",
    "                \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n",
    "                \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n",
    "                \"data_retrieved_at\": retrieval_time\n",
    "            }\n",
    "\n",
    "            # Append the weather item to the list\n",
    "            weather_items.append(weather_item)\n",
    "\n",
    "    # Create a DataFrame from the list of weather items\n",
    "    weather_df = pd.DataFrame(weather_items)\n",
    "\n",
    "    # Convert 'forecast_time' and 'data_retrieved_at' columns to datetime\n",
    "    weather_df[\"forecast_time\"] = pd.to_datetime(weather_df[\"forecast_time\"])\n",
    "    weather_df[\"data_retrieved_at\"] = pd.to_datetime(weather_df[\"data_retrieved_at\"])\n",
    "\n",
    "    return weather_df\n",
    "\n",
    "def send_weather_data(weather_df, connection_string):\n",
    "    engine = create_engine(connection_string)\n",
    "    weather_df.to_sql('weather_data',\n",
    "                      if_exists='replace',\n",
    "                      con=engine,\n",
    "                      index=False,\n",
    "                      method='multi',  # Use 'multi' method for faster inserts\n",
    "                      chunksize=1000)\n",
    "    print(f\"Weather data successfully sent to MySQL database!\")\n",
    "\n",
    "retreiving_and_sending_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a61426-57ac-4ad9-9fd6-a82458416fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from pytz import timezone\n",
    "\n",
    "icao_list = [\"EDDB\", \"EDDH\", \"EDDM\", \"EDDS\", \"EDDF\", \"EDDL\"]\n",
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\", \"Stuttgart\", \"Frankfurt\", \"Düsseldorf\"]\n",
    "connection_string='mysqlpass'\n",
    "\n",
    "def retreiving_and_sending_airport_data():\n",
    "    airport_df = get_airport_data(icao_list)\n",
    "    send_airport_data(airport_df, connection_string)\n",
    "    return \"Data has been updated\"\n",
    "\n",
    "\n",
    "def get_airport_data(icao_list):\n",
    "  api_key = 'my-api'\n",
    "\n",
    "  berlin_timezone = timezone('Europe/Berlin')\n",
    "  today = datetime.now(berlin_timezone).date()\n",
    "  tomorrow = (today + timedelta(days=1))\n",
    "\n",
    "  flight_items = []\n",
    "\n",
    "  for icao in icao_list:\n",
    "    # the api can only make 12 hour calls, therefore, 2 12 hour calls make a full day\n",
    "    # using the nested lists below we can make a morning call and extract the data\n",
    "    # then make an afternoon call and extract the data\n",
    "    times = [[\"00:00\",\"11:59\"],\n",
    "             [\"12:00\",\"23:59\"]]\n",
    "\n",
    "    for time in times:\n",
    "      url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{icao}/{date}T{time_1}/{date}T{time_2}\"\n",
    "\n",
    "      querystring = {\"withLeg\":\"true\",\n",
    "                    \"direction\":\"Arrival\",\n",
    "                    \"withCancelled\":\"false\",\n",
    "                    \"withCodeshared\":\"true\",\n",
    "                    \"withCargo\":\"false\",\n",
    "                    \"withPrivate\":\"false\"}\n",
    "\n",
    "      headers = {\n",
    "          'x-rapidapi-host': \"aerodatabox.p.rapidapi.com\",\n",
    "          'x-rapidapi-key': api_key\n",
    "          }\n",
    "\n",
    "      response = requests.request(\"GET\",\n",
    "                                  url,\n",
    "                                  headers = headers,\n",
    "                                  params = querystring)\n",
    "\n",
    "      flights_json = response.json()\n",
    "\n",
    "      retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7430155-5595-42d2-b61d-1a484c0881e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_airport_data(icao_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d18d0e-51b6-47b0-9753-3eef970eb64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c4dba-6f84-4b58-955b-390bc9a01c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0e3600f3-1ead-49d5-9cde-f0f1808734a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight data successfully sent to MySQL database!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data has been updated'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from pytz import timezone\n",
    "\n",
    "icao_list = [\"EDDB\", \"EDDH\", \"EDDM\", \"EDDS\", \"EDDF\", \"EDDL\"]\n",
    "connection_string = 'mysql+pymysql://root:Robertalex4!@127.0.0.1:3306/sql_workshop_cities'\n",
    "\n",
    "\n",
    "def retreiving_and_sending_flights_data():\n",
    "    flights_df = get_flight_data(icao_list)\n",
    "    send_flights_data(flights_df, connection_string)\n",
    "    return \"Data has been updated\"\n",
    "\n",
    "\n",
    "def get_flight_data(icao_list):\n",
    "    api_key = 'my-api'\n",
    "\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    today = datetime.now(berlin_timezone).date()\n",
    "    tomorrow = (today + timedelta(days=1))\n",
    "\n",
    "    flight_items = []\n",
    "\n",
    "    for icao in icao_list:\n",
    "        times = [[\"00:00\", \"11:59\"],\n",
    "                 [\"12:00\", \"23:59\"]]\n",
    "\n",
    "        for time in times:\n",
    "            time_1, time_2 = time\n",
    "            url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{icao}/{tomorrow}T{time_1}/{tomorrow}T{time_2}\"\n",
    "        \n",
    "            \n",
    "\n",
    "            querystring = {\"withLeg\": \"true\",\n",
    "                           \"direction\": \"Arrival\",\n",
    "                           \"withCancelled\": \"false\",\n",
    "                           \"withCodeshared\": \"true\",\n",
    "                           \"withCargo\": \"false\",\n",
    "                           \"withPrivate\": \"false\"}\n",
    "\n",
    "            headers = {\n",
    "                'x-rapidapi-host': \"aerodatabox.p.rapidapi.com\",\n",
    "                'x-rapidapi-key': api_key\n",
    "            }\n",
    "\n",
    "            response = requests.request(\"GET\",\n",
    "                                        url,\n",
    "                                        headers=headers,\n",
    "                                        params=querystring)\n",
    "\n",
    "            flights_json = response.json()\n",
    "\n",
    "            retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            for item in flights_json[\"arrivals\"]:\n",
    "                flight_item = {\n",
    "                    \"airport_icao\": icao,\n",
    "                    \"departure_airport_icao\": item[\"departure\"][\"airport\"].get(\"icao\", None),\n",
    "                    \"scheduled_arrival_time\": item[\"arrival\"][\"scheduledTime\"].get(\"local\", None),\n",
    "                    \"flight_number\": item.get(\"number\", None),\n",
    "                    \"data_retrieved_at\": retrieval_time\n",
    "                }\n",
    "\n",
    "                flight_items.append(flight_item)\n",
    "\n",
    "    flights_df = pd.DataFrame(flight_items)\n",
    "    flights_df[\"scheduled_arrival_time\"] = flights_df[\"scheduled_arrival_time\"].str[:-6]\n",
    "    flights_df[\"scheduled_arrival_time\"] = pd.to_datetime(flights_df[\"scheduled_arrival_time\"])\n",
    "    flights_df[\"data_retrieved_at\"] = pd.to_datetime(flights_df[\"data_retrieved_at\"])\n",
    "\n",
    "    return flights_df\n",
    "\n",
    "\n",
    "def send_flights_data(flights_df, connection_string):\n",
    "    flights_df.to_sql('flights',\n",
    "                  if_exists='replace',  # Replace existing table\n",
    "                  con=connection_string,\n",
    "                  index=False,\n",
    "                  method='multi',\n",
    "                  chunksize=1000)\n",
    "    print(f\"Flight data successfully sent to MySQL database!\")\n",
    "\n",
    "\n",
    "retreiving_and_sending_flights_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab79924-c97b-48ca-bafb-104bbeedac62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d6595-69dc-4a96-aa44-67c6835b3c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flights_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f5def502-a978-4e23-b575-24e01e5916a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'53°37′49″N 009°59′28″E\\ufeff / \\ufeff53.63028°N 9.99111°E\\ufeff / 53.63028; 9.99111'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "response = requests.get(url)\n",
    "city_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "url = f\"https://en.wikipedia.org/wiki/Hamburg_Airport\"\n",
    "\n",
    "airport_iata = city_soup.find(class_=\"nowrap\").find_next(\"span\").get_text()#iata\n",
    "airport_icao = city_soup.find_all(class_=\"nowrap\")\n",
    "airport_icao = airport_icao[1].find_next(\"span\").get_text()\n",
    "airport_nickname = city_soup.find(class_=\"nickname\").get_text()  \n",
    "latitude = city_soup.find(class_=\"latitude\").get_text(\n",
    "\n",
    "\n",
    "passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d35a219d-a0bc-4b2d-8004-b31152a6f904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_id airport_iata airport_icao  \\\n",
      "0        1          BER         EDDB   \n",
      "1        2          HAM         EDDH   \n",
      "2        3          MUC         EDDM   \n",
      "3        4          STR         EDDS   \n",
      "4        5          FRA         EDDF   \n",
      "5        6          DUS         EDDL   \n",
      "\n",
      "                                  airport_name   latitude  longitude  \n",
      "0  Flughafen Berlin Brandenburg “Willy Brandt“  52.366667  13.503333  \n",
      "1                            Flughafen Hamburg  53.630278   9.991111  \n",
      "2                            Flughafen München  48.353889  11.786111  \n",
      "3                          Flughafen Stuttgart  48.690000   9.221944  \n",
      "4                     Flughafen Frankfurt Main  50.033333   8.570556  \n",
      "5                         Flughafen Düsseldorf  51.289444   6.766667  \n",
      "   city_id  country  population   latitude  longitude\n",
      "0        1  Germany   3850809.0  52.520000  13.405000\n",
      "1        2  Germany   1945532.0        NaN        NaN\n",
      "2        3  Germany   1512491.0  48.137500  11.575000\n",
      "3        4  Germany    626275.0  48.777500   9.180000\n",
      "4        5  Germany         NaN  50.110556   8.682222\n",
      "5        6  Germany    619477.0        NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Function to scrape airport data\n",
    "def scrape_airport_data(url, city_id):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extracting data using Beautiful Soup\n",
    "    airport_iata = soup.find(class_=\"nowrap\").find_next(\"span\").get_text()\n",
    "    airport_icao = soup.find_all(class_=\"nowrap\")[1].find_next(\"span\").get_text()\n",
    "    airport_nickname = soup.find(class_=\"nickname\").get_text()\n",
    "    latitude = soup.find(class_=\"latitude\").get_text()\n",
    "    longitude= soup.find(class_=\"longitude\").get_text()\n",
    "\n",
    "    return {\n",
    "        \"city_id\": city_id,\n",
    "        \"airport_iata\": airport_iata,\n",
    "        \"airport_icao\": airport_icao,\n",
    "        \"airport_name\": airport_nickname,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude\n",
    "    }\n",
    "\n",
    "def transform_coordinates(lat_str, lon_str):\n",
    "    def dms_to_dd(degrees, minutes, seconds, direction):\n",
    "        dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "        if direction == 'S' or direction == 'W':\n",
    "            dd *= -1\n",
    "        return dd\n",
    "\n",
    "    try:\n",
    "        lat_parts = re.split('[^\\d.]+', lat_str)\n",
    "        lon_parts = re.split('[^\\d.]+', lon_str)\n",
    "\n",
    "        if len(lat_parts) >= 4 and len(lon_parts) >= 4:\n",
    "            lat_deg, lat_min, lat_sec, lat_dir = lat_parts[:4]\n",
    "            lon_deg, lon_min, lon_sec, lon_dir = lon_parts[:4]\n",
    "\n",
    "            lat_decimal = dms_to_dd(lat_deg, lat_min, lat_sec, lat_dir)\n",
    "            lon_decimal = dms_to_dd(lon_deg, lon_min, lon_sec, lon_dir)\n",
    "\n",
    "            return lat_decimal, lon_decimal\n",
    "        else:\n",
    "            raise ValueError(\"Invalid format for latitude or longitude\")\n",
    "    except ValueError:\n",
    "        return None, None \n",
    "    \n",
    "# List of cities\n",
    "cities = [\"Berlin\", \"Hamburg\", \"Munich\", \"Stuttgart\", \"Frankfurt\", \"Düsseldorf\"]\n",
    "\n",
    "# Create an empty list to store airport data\n",
    "airport_data_list = []\n",
    "\n",
    "# Iterate through each city and scrape airport data\n",
    "for city_id, city_name in enumerate(cities, start=1):\n",
    "    # Construct the URL for the city's airport Wikipedia page\n",
    "    city_wiki_url = f\"https://www.wikipedia.org/wiki/{city_name}_Airport\"\n",
    "\n",
    "    # Scrape airport data and append to the list\n",
    "    airport_data = scrape_airport_data(city_wiki_url, city_id)\n",
    "    airport_data_list.append(airport_data)\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "airports_df = pd.DataFrame(airport_data_list)\n",
    "\n",
    "airports_df[['latitude', 'longitude']] = airports_df.apply(lambda row: transform_coordinates(row['latitude'], row['longitude']), axis=1, result_type='expand')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(airports_df)\n",
    "\n",
    "airports_df.to_sql('airports_data',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)\n",
    "print(cities_facts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f0cec-71f2-4ca2-b351-78a093556974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76460011-8468-4423-ae1f-6bece820903b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491314b-48cf-4d7d-8067-46127322fe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
